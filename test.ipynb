{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137199ff",
   "metadata": {},
   "source": [
    "# Dataset assumptions and instructions\n",
    "\n",
    "- Place your dataset as `data.csv` in the project root (or change the `DATA_PATH` variable below).\n",
    "- The notebook assumes a regression task. If your target column is named `target`, it will be used.\n",
    "  Otherwise the last column will be treated as the target.\n",
    "- The notebook performs simple cleaning: drops duplicates, fills numeric NAs with median, categorical NAs with mode, and one-hot-encodes categoricals.\n",
    "- It trains a scikit-learn `LinearRegression` model and prints MSE and R^2, then saves the model to `linear_model.joblib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3472c56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 2.3.3\n",
      "numpy 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Imports (install scikit-learn, pandas, joblib beforehand if needed)\n",
    "import os\n",
    "import pandas as pand\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Helper: prints environment info to help debugging imports\n",
    "print('pandas', pand.__version__)\n",
    "print('numpy', np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a23616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATA_PATH = 'data.csv'  # change if your file has a different name or path\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Place your CSV there or update DATA_PATH.\")\n",
    "\n",
    "df = pand.read_csv(DATA_PATH)\n",
    "print('Loaded', len(df), 'rows and', len(df.columns), 'columns')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column\n",
    "if 'target' in df.columns:\n",
    "    target_col = 'target'\n",
    "else:\n",
    "    # use last column as target by default\n",
    "    target_col = df.columns[-1]\n",
    "print('Using target column:', target_col)\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[target_col])  # must have target\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(float)\n",
    "\n",
    "# Handle missing values: numeric -> median, categorical -> mode\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    med = X[c].median()\n",
    "    X[c] = X[c].fillna(med)\n",
    "for c in cat_cols:\n",
    "    mode = X[c].mode(dropna=True)\n",
    "    if len(mode) > 0:\n",
    "        X[c] = X[c].fillna(mode[0])\n",
    "    else:\n",
    "        X[c] = X[c].fillna('')\n",
    "\n",
    "# One-hot encode categoricals\n",
    "if len(cat_cols) > 0:\n",
    "    X = pand.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "print('Feature matrix shape after encoding:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ee62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split and scaling\n",
    "RANDOM_STATE = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'R^2: {r2:.4f}')\n",
    "\n",
    "# Save model and scaler\n",
    "# Save both model and scaler together\n",
    "joblib.dump({'model': model, 'scaler': scaler}, 'linear_model.joblib')\n",
    "print('Saved model and scaler to linear_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
